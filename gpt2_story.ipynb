{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631734,
     "status": "ok",
     "timestamp": 1603986718485,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "yG3O0YcbDGxR",
    "outputId": "b823eebb-75bb-44a6-ccb5-2bcaf2490998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# home_directory = ''\n",
    "home_directory = 'drive/My Drive/Colab Notebooks/poe/'\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639625,
     "status": "ok",
     "timestamp": 1603986726393,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "JYKPbTRoDUtz",
    "outputId": "6a2a0b92-9dfd-4795-f0f8-98971d24375c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 6.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 38.8MB/s \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 37.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting tokenizers==0.9.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 40.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a85e007accd1b2afbe039e6a8ae3c47a56982609e01d0a26538dc359fcf9d5d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 641623,
     "status": "ok",
     "timestamp": 1603986728404,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "QvN_A8yNEmuL",
    "outputId": "acea2910-6c31-45c5-b8a6-e00f526bf1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ojuAdlpDABj"
   },
   "source": [
    "# Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "executionInfo": {
     "elapsed": 646771,
     "status": "ok",
     "timestamp": 1603986733555,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "U28UnrvEDABk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "executionInfo": {
     "elapsed": 648498,
     "status": "ok",
     "timestamp": 1603986735284,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "c0Sq2b2qDABn"
   },
   "outputs": [],
   "source": [
    "story_df = pd.read_csv(home_directory + 'poe_short_stories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTbANtaYDABy"
   },
   "source": [
    "# Clean Short Story Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 648471,
     "status": "ok",
     "timestamp": 1603986735296,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "YqY0_q26DABz",
    "outputId": "08749e84-80e4-43af-f489-27776ce7eccf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>first_published_in</th>\n",
       "      <th>classification</th>\n",
       "      <th>notes</th>\n",
       "      <th>normalized_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>* PHILOSOPHY OF FURNITURE</td>\n",
       "      <td>In the internal decoration, if not in the exte...</td>\n",
       "      <td>?</td>\n",
       "      <td>May 1840</td>\n",
       "      <td>?</td>\n",
       "      <td>Essay</td>\n",
       "      <td>?</td>\n",
       "      <td>May 1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MAELZEL’S CHESS-PLAYER</td>\n",
       "      <td>PERHAPS no exhibition of the kind has ever eli...</td>\n",
       "      <td>?</td>\n",
       "      <td>April 1836</td>\n",
       "      <td>?</td>\n",
       "      <td>Essay</td>\n",
       "      <td>?</td>\n",
       "      <td>April 1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>OLD ENGLISH POETRY</td>\n",
       "      <td>IT should not be doubted that at least one-thi...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Essay</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>THE POETIC PRINCIPLE</td>\n",
       "      <td>IN speaking of the Poetic Principle, I have no...</td>\n",
       "      <td>?</td>\n",
       "      <td>August 17, 1849</td>\n",
       "      <td>?</td>\n",
       "      <td>Essay</td>\n",
       "      <td>?</td>\n",
       "      <td>August 1849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  ... normalized_date\n",
       "62  * PHILOSOPHY OF FURNITURE  ...        May 1840\n",
       "63     MAELZEL’S CHESS-PLAYER  ...      April 1836\n",
       "64         OLD ENGLISH POETRY  ...               ?\n",
       "67       THE POETIC PRINCIPLE  ...     August 1849\n",
       "\n",
       "[4 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df[story_df.classification=='Essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 648470,
     "status": "ok",
     "timestamp": 1603986735297,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "1CKINt0KDAB1"
   },
   "outputs": [],
   "source": [
    "# remove essays (non-fiction)\n",
    "story_df = story_df.loc[story_df['classification'] != 'Essay'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 648866,
     "status": "ok",
     "timestamp": 1603986735723,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "2AgvJhqADAB7",
    "outputId": "22645592-57d3-4f2d-eab8-db8c9caa81f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>first_published_in</th>\n",
       "      <th>classification</th>\n",
       "      <th>notes</th>\n",
       "      <th>normalized_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>THE PIT AND THE PENDULUM</td>\n",
       "      <td>Impia tortorum longos hic turba furores Sangui...</td>\n",
       "      <td>The Pit and the Pendulum</td>\n",
       "      <td>? 1843</td>\n",
       "      <td>The Gift: A Christmas and New Year's Present</td>\n",
       "      <td>Horror</td>\n",
       "      <td>?</td>\n",
       "      <td>? 1843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                     title  ... notes normalized_date\n",
       "48     48  THE PIT AND THE PENDULUM  ...     ?          ? 1843\n",
       "\n",
       "[1 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df[story_df.normalized_date == '? 1843']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyK3JdWdDAB9"
   },
   "source": [
    "\"Annual issues were published in the fall of the preceding year.  The month for publication of this issue is thought to be October due to a reprint of \"The Pit and the Pendulum\" in the October 22, 1842 New York Spectator\"\n",
    "\n",
    "Source:  http://www.isfdb.org/cgi-bin/pl.cgi?296127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 648863,
     "status": "ok",
     "timestamp": 1603986735724,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "bjO4BN5cDAB9"
   },
   "outputs": [],
   "source": [
    "story_df.loc[story_df['title'] == 'THE PIT AND THE PENDULUM', 'normalized_date'] = 'October 1842'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 648851,
     "status": "ok",
     "timestamp": 1603986735725,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "sGGzTS0jDACE",
    "outputId": "93b43606-e7fd-4789-f0bf-ce081c9a8b42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>first_published_in</th>\n",
       "      <th>classification</th>\n",
       "      <th>notes</th>\n",
       "      <th>normalized_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ELEONORA</td>\n",
       "      <td>Sub conservatione formae specificae salva anim...</td>\n",
       "      <td>Eleonora</td>\n",
       "      <td>? 1841</td>\n",
       "      <td>The Gift for 1842</td>\n",
       "      <td>Romance</td>\n",
       "      <td>?</td>\n",
       "      <td>? 1841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     title  ... notes normalized_date\n",
       "6      6  ELEONORA  ...     ?          ? 1841\n",
       "\n",
       "[1 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_df[story_df.normalized_date == '? 1841']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKQMkGWzDACJ"
   },
   "source": [
    "Since Eleonara appeared in the same publication (The Gift) as The Pit and the Pendulum, we can assume it had a similar date of publication (October of the previous year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 648853,
     "status": "ok",
     "timestamp": 1603986735729,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "nBWHRVFDDACJ"
   },
   "outputs": [],
   "source": [
    "story_df.loc[story_df['title'] == 'ELEONORA', 'normalized_date'] = 'October 1841'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvAA-x3qDADW"
   },
   "source": [
    "# Text Generation - GPT-2\n",
    "## Process Text and Create Dataset\n",
    "\n",
    "http://jalammar.github.io/illustrated-gpt2/\n",
    "https://medium.com/@stasinopoulos.dimitrios/a-beginners-guide-to-training-and-generating-text-using-gpt2-c2f2e1fbd10a\n",
    "https://huggingface.co/transformers/model_doc/gpt2.html\n",
    "https://towardsdatascience.com/step-by-step-guide-on-how-to-train-gpt-2-on-books-using-google-colab-b3c6fa15fef0\n",
    "https://medium.com/swlh/fine-tuning-gpt-2-for-magic-the-gathering-flavour-text-generation-3bafd0f9bb93\n",
    "https://colab.research.google.com/drive/16UTbQOhspQOF3XlxDFyI28S-0nAkTzk_#scrollTo=v4XhewaV93-_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 682850,
     "status": "ok",
     "timestamp": 1603986769941,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "mqDVvA-3DADW"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 73\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 4\n",
    "SAMPLE_EVERY = 100\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "1f35359477ea405b9789ff24e250546b",
      "b70cae5ca73a4ac3a742da150df0d649",
      "e272f30f056b4cf1b1f92dfe50e045bc",
      "d2172bc18d6a420a8d7e0a1bb3b69e23",
      "316c4b609fdc471e8b21a7c9338f19e5",
      "964d71dc60fe459cb957453e47937e50",
      "5763231ceb434c55ad784aa03afbe45d",
      "56ac40250b79440bbe0d95933c9ae8e8",
      "d747e350678543f6ae0c237cecaa6e3f",
      "f6521c70ba724b268103338c2e4d8885",
      "0c147b1df0d14336a73811fb85044efd",
      "d32e5580197341898c8817fcef34eb56",
      "fc0dda773fe5482ba358f55b9b277306",
      "38a0d2b24aab431aa2ce3907e3c4c7ff",
      "c337b040a7514d6384b50bece66cb8ed",
      "516a3444976945be8f0a93810d9c6e03"
     ]
    },
    "executionInfo": {
     "elapsed": 685385,
     "status": "ok",
     "timestamp": 1603986772478,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "mr2yKiTrDADY",
    "outputId": "f05ddac6-5b07-4ea2-d401-4bda9b77654b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f35359477ea405b9789ff24e250546b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d747e350678543f6ae0c237cecaa6e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>'}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690071,
     "status": "ok",
     "timestamp": 1603986777172,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "xLfuf3U4DADa",
    "outputId": "86bf3119-76ad-4f43-f006-f7397898848c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9052 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "max_story_length = max([len(tokenizer.encode(story)) for story in story_df['text'].values])\n",
    "min_story_length = min([len(tokenizer.encode(story)) for story in story_df['text'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690066,
     "status": "ok",
     "timestamp": 1603986777174,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "NU0hMFDaDADc",
    "outputId": "230ea7c8-055c-4c2a-db29-35580f136a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Edgar Allen Poe Short Story: 25411 tokens long.\n",
      "Shortest Edgar Allen Poe Short Story: 1305 tokens long.\n"
     ]
    }
   ],
   "source": [
    "print('Longest Edgar Allen Poe Short Story:', max_story_length, 'tokens long.')\n",
    "print('Shortest Edgar Allen Poe Short Story:', min_story_length, 'tokens long.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 690234,
     "status": "ok",
     "timestamp": 1603986777363,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "V5nVm6ZKDADq"
   },
   "outputs": [],
   "source": [
    "class PoeStoryDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, tokenizer, gpt2_type='gpt2', max_length=MAX_SEQUENCE_LENGTH):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        for i in data:\n",
    "            for j in split_into_sentences(i):\n",
    "            \n",
    "                encodings_dict = tokenizer('<BOS>' + j + '<EOS>',\n",
    "                                           truncation=True,\n",
    "                                           max_length=max_length,\n",
    "                                           padding='max_length'\n",
    "                                          )\n",
    "\n",
    "                self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "                self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 697840,
     "status": "ok",
     "timestamp": 1603986784974,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "F2X7R8B3DADs"
   },
   "outputs": [],
   "source": [
    "story_dataset = PoeStoryDataset(story_df['text'].values, tokenizer, max_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rw3cxQjKDADu"
   },
   "source": [
    "### Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 697841,
     "status": "ok",
     "timestamp": 1603986784976,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "66YPjdiyDADu"
   },
   "outputs": [],
   "source": [
    "def train_val_split(split, dataset):\n",
    "    train_size = int(split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    return train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 697839,
     "status": "ok",
     "timestamp": 1603986784977,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "bdmHhsPbDADw"
   },
   "outputs": [],
   "source": [
    "story_train_size, story_val_size = train_val_split(0.8, story_dataset)\n",
    "\n",
    "# random split imported from troch.utils\n",
    "story_train_dataset, story_val_dataset = random_split(story_dataset, [story_train_size, story_val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVmKeOS_DADy"
   },
   "source": [
    "### Apply Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697833,
     "status": "ok",
     "timestamp": 1603986784978,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "Vjgbzym_DADy",
    "outputId": "5a79758d-1869-4621-8346-46564d4dea02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1bf0317420>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fk86UcTDAD2"
   },
   "source": [
    "### Instantiate DataLoaders and Define Model Creation Function\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 697830,
     "status": "ok",
     "timestamp": 1603986784978,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "IupduXEyDAD2"
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, bs):\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  sampler=RandomSampler(train_dataset),\n",
    "                                  batch_size=bs)\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                sampler=SequentialSampler(val_dataset),\n",
    "                                batch_size=bs)\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 697829,
     "status": "ok",
     "timestamp": 1603986784979,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "aNrtN6Y5DAD4"
   },
   "outputs": [],
   "source": [
    "story_train_dataloader, story_val_dataloader = create_dataloaders(story_train_dataset, story_val_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "a47326a853ef432b9585cf96690539f7",
      "ab04323c16e84978a5f873d13c8ade68",
      "5547c013bcad4037a328262600d1fafd",
      "1b78c07bb081425a9c553f4b018c9e5c",
      "4bc2ae74489c4a3dbb4be0cbbf9ee93b",
      "c7241323cf914ecbb4603ccccd98705f",
      "15ce4962eac74f758356243cc2f6a7c2",
      "1bbf654d23374169998e2c348facff01"
     ]
    },
    "executionInfo": {
     "elapsed": 698756,
     "status": "ok",
     "timestamp": 1603986785908,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "OtPCGDO9DAD6",
    "outputId": "36ac0fa6-68d6-4a81-b7ba-06b7cec15926"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47326a853ef432b9585cf96690539f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions=MAX_SEQUENCE_LENGTH).from_pretrained('gpt2', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 698756,
     "status": "ok",
     "timestamp": 1603986785909,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "vtN2HoCSDAD8"
   },
   "outputs": [],
   "source": [
    "# helper function for logging time\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 698754,
     "status": "ok",
     "timestamp": 1603986785909,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "cVAc8qwpDAD-"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "learning_rate = 5e-4\n",
    "eps = 1e-8\n",
    "warmup_steps = 1e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 710223,
     "status": "ok",
     "timestamp": 1603986797382,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "28bCokPoDrHM"
   },
   "outputs": [],
   "source": [
    "# create text generation seed prompt\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "prompt = \"<BOS>\"\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "generated = generated.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 710224,
     "status": "ok",
     "timestamp": 1603986797385,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "91z0CIlTDAD_"
   },
   "outputs": [],
   "source": [
    "def create_model(train_dataloader, val_dataloader, file_name):\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    model.cuda()\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
    "\n",
    "    total_steps = len(train_dataloader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=warmup_steps,\n",
    "                                                num_training_steps=total_steps)\n",
    "    \n",
    "    total_t0 = time.time()\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch_i in range(0, EPOCHS):\n",
    "\n",
    "        print(f'Epoch {epoch_i + 1} of {EPOCHS}')\n",
    "\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[0].to(device)\n",
    "            b_masks = batch[1].to(device)\n",
    "\n",
    "            model.zero_grad()        \n",
    "\n",
    "            outputs = model(b_input_ids,\n",
    "                            labels=b_labels, \n",
    "                            attention_mask=b_masks,\n",
    "                            token_type_ids=None)\n",
    "\n",
    "            loss = outputs[0]  \n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            total_train_loss += batch_loss\n",
    "\n",
    "            if step % SAMPLE_EVERY == 0 and step != 0:\n",
    "                \n",
    "                model.eval()\n",
    "                sample_outputs = model.generate(\n",
    "                                        generated,\n",
    "                                        do_sample=True,   \n",
    "                                        top_k=50, \n",
    "                                        max_length=200,\n",
    "                                        top_p=0.95, \n",
    "                                        num_return_sequences=1\n",
    "                                    )\n",
    "                for i, sample_output in enumerate(sample_outputs):\n",
    "                      print(f'Example output: {tokenizer.decode(sample_output, skip_special_tokens=True)}')\n",
    "\n",
    "                model.train()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        print('Evaluating Model')\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[0].to(device)\n",
    "            b_masks = batch[1].to(device)\n",
    "\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                outputs  = model(b_input_ids,  \n",
    "                                 attention_mask=b_masks,\n",
    "                                 labels=b_labels)\n",
    "\n",
    "                loss = outputs[0]  \n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            total_eval_loss += batch_loss        \n",
    "\n",
    "        avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "\n",
    "        validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "        print(f'Validation loss: {avg_val_loss}. Validation Time: {validation_time}')\n",
    "\n",
    "    print(f'Total training took {format_time(time.time()-total_t0)}')\n",
    "\n",
    "    torch.save(model.state_dict(), home_directory + file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeAjLD_oGJQf"
   },
   "source": [
    "# Create Story Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8915376a612e4d4a86797b6b18fead2d",
      "24b4fa70fee64177891166b81c279a1d",
      "60d45f1c2fda472da03a8d9a12586cbd",
      "1e0b30803881441988419227179679b6",
      "aaea1ccf6fb94a04b015959525e14c6f",
      "72008ffdf1b54cf6b17a43a29aa01326",
      "6e644b8638ec46ac85c6873735ad50a0",
      "0c03cb12edbd4dffa704a1bf0198e2ce"
     ]
    },
    "executionInfo": {
     "elapsed": 17233808,
     "status": "ok",
     "timestamp": 1604003320984,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "zkQk7CeJFmcu",
    "outputId": "f58d674f-1350-4869-cb74-2e85724c2ff5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8915376a612e4d4a86797b6b18fead2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 of 3044. Loss:0.11765287816524506. Time:0:02:01\n",
      "Example output:  and all that I have seen, was just my way of getting to the point whereI was sure of nothing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 of 3044. Loss:0.5541245937347412. Time:0:04:07\n",
      "Example output: There is no doubt that the present state of our society could not possibly have been induced by the influence of a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 of 3044. Loss:0.18502269685268402. Time:0:06:12\n",
      "Example output: —determinism—why I felt it necessary to believe it, and, for the sake of this opinion, to say it—no.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 of 3044. Loss:0.1696680337190628. Time:0:08:18\n",
      "Example output: By this, it will be apprehended that the latter is a most extraordinary matter which, as my father had just observed, it would very much be impossible if I not, for example, be imagined to find a more profound and peculiar feeling in a man than I, who is an adventurer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 of 3044. Loss:0.3560437560081482. Time:0:10:23\n",
      "Example output: Now for the second time I lay up my hands upon him, and I threw him some serious matter to my attention.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600 of 3044. Loss:0.2961936295032501. Time:0:12:29\n",
      "Example output: I have some kind of idea of how to proceed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700 of 3044. Loss:0.26128166913986206. Time:0:14:34\n",
      "Example output: How well are we to look for an hour?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800 of 3044. Loss:0.2666405737400055. Time:0:16:40\n",
      "Example output: ” “No”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900 of 3044. Loss:0.2653592526912689. Time:0:18:46\n",
      "Example output: The most remarkable thing about the man is the idea, I said at length, of what he had accomplished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 of 3044. Loss:0.2845943570137024. Time:0:20:51\n",
      "Example output: In the meantime, however, this circumstance is properly admitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100 of 3044. Loss:0.11345622688531876. Time:0:22:57\n",
      "Example output: ”      “We are here, the Prefect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200 of 3044. Loss:0.24247710406780243. Time:0:25:03\n",
      "Example output: This is the first example of a joint effort of a certain degree.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300 of 3044. Loss:0.2978390157222748. Time:0:27:09\n",
      "Example output: We came to the end of the street, and, at length, a black gable of the most magnificent design lay erect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400 of 3044. Loss:0.1922534704208374. Time:0:29:15\n",
      "Example output: But here again the theme was the theme of the novel; and the tone was in the tone of the novel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500 of 3044. Loss:0.21229246258735657. Time:0:31:21\n",
      "Example output: He was a great trouble with a thousand different persons—but I thought it more proper to let him be brought home within days than to let him be dragged in jail in his hurry to safety and return home at once.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600 of 3044. Loss:0.2398640513420105. Time:0:33:28\n",
      "Example output: “Let the people tell me that she who is supposed to be this woman was a very kind gentleman, and to have any reference in its particulars would have been very remarkable, for there was no other word for that term than,” replied the Doctor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1700 of 3044. Loss:0.13351522386074066. Time:0:35:34\n",
      "Example output: They knew it”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800 of 3044. Loss:0.20892949402332306. Time:0:37:40\n",
      "Example output: “And what is your name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1900 of 3044. Loss:0.17380990087985992. Time:0:39:46\n",
      "Example output: Having satisfied myself with my senses, I opened the drawer and carefully turned the valve.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000 of 3044. Loss:0.29052186012268066. Time:0:41:52\n",
      "Example output: I took it, however, as soon as I saw that you remained at the residence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2100 of 3044. Loss:0.12633587419986725. Time:0:43:57\n",
      "Example output: She also became an old lady, and this was the last she observed to be observed in Paris.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200 of 3044. Loss:0.20419345796108246. Time:0:46:02\n",
      "Example output: In these latter two particulars, however, I gave to you an interest in the character of the personage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2300 of 3044. Loss:0.21723635494709015. Time:0:48:08\n",
      "Example output: The two men, who were so greatly astonished, and so long puzzled, upon seeing these passages in their wild agitation, succeeded in rendering them readily and easily understood, by calling them in their wildest, most thrilling, and most earnest manner, to which I have not been able to bear a reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400 of 3044. Loss:0.17236259579658508. Time:0:50:13\n",
      "Example output: In the short period of time spent, Mr. C. B. seemed much on the brink of death.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500 of 3044. Loss:0.1787150651216507. Time:0:52:18\n",
      "Example output: A second of a kind, now, appeared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600 of 3044. Loss:0.26700448989868164. Time:0:54:23\n",
      "Example output: I was the editor of “House”—“and I really have no account of this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2700 of 3044. Loss:0.1773548424243927. Time:0:56:29\n",
      "Example output: A full report is in my possession.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800 of 3044. Loss:0.09261709451675415. Time:0:58:34\n",
      "Example output: These creatures of the nature and color were all adapted to the landscape.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2900 of 3044. Loss:0.38284212350845337. Time:1:00:40\n",
      "Example output: I spoke the voice of a gentleman of his own; and the language of his own was very clear; and it was obvious that he spoke not to me altogether:        I will tell you that he smiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000 of 3044. Loss:0.2477523237466812. Time:1:02:45\n",
      "Example output: He could not help perceiving the figure closely around him; although in truth it was his own personal creation.\n",
      "Average Training Loss: 0.25242053055536107. Epoch time: 1:03:42\n",
      "Evaluating Model\n",
      "Validation loss: 0.21287860500863373. Validation Time: 0:05:11\n",
      "Epoch 2 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 of 3044. Loss:0.16546602547168732. Time:0:02:01\n",
      "Example output: —and all the world has known!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 of 3044. Loss:0.09306070953607559. Time:0:04:06\n",
      "Example output: The words “Arrival at Sullivan’ seem sufficiently obvious,” but I have also done so.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 of 3044. Loss:0.11480526626110077. Time:0:06:11\n",
      "Example output: The latter was my friend, and I had all the means of observing the movements of the parties.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 of 3044. Loss:0.09520089626312256. Time:0:08:16\n",
      "Example output: ” “No, sir,”       “That’s a long sentence, sir!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 of 3044. Loss:0.3461945652961731. Time:0:10:21\n",
      "Example output: It is so far, now, from being known that I think it proper to take me at once into one of the most unaccountable and dangerous investigations of the year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600 of 3044. Loss:0.1860598772764206. Time:0:12:27\n",
      "Example output: “And now, it is, for the purpose of referring to a very brief account of these peculiarities, and the conclusions to which I have drawn these conclusions, that I have endeavored in the present case to establish any connection, or a parallel, with the arguments entertained by Le Blanc et il vell.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700 of 3044. Loss:0.12740592658519745. Time:0:14:32\n",
      "Example output: Hereupon I fancied myself getting dizzy from the sensations in which I put myself to repose.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800 of 3044. Loss:0.1493404060602188. Time:0:16:37\n",
      "Example output: “What shall I say about the circumstances of my murder?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900 of 3044. Loss:0.17580676078796387. Time:0:18:43\n",
      "Example output: I have not put into practice a theory so well conceived as that entertained by Gorgias Amontillado’s “Owl”; but in such a case the probability of such theory being adopted, of course, in all otherries, is at least\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 of 3044. Loss:0.33380457758903503. Time:0:20:48\n",
      "Example output: —must I confess that the man at all was a fool?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100 of 3044. Loss:0.14823566377162933. Time:0:22:53\n",
      "Example output: “In speaking the language of Plato, however, I have been urged, very forcibly, to term, “Old Charon, or Mr. Pansy, or Mr. Bentinck”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200 of 3044. Loss:0.224165678024292. Time:0:24:59\n",
      "Example output: Even his own personal idiosyncrasy of style would naturally have led him to perceive that his own opinions were altogether untictillably true.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300 of 3044. Loss:0.3290710747241974. Time:0:27:04\n",
      "Example output: The house, however, was still quite over, and, to my vexation, I betook myself to its owner—I felt quite resigned to the experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400 of 3044. Loss:0.2809046804904938. Time:0:29:10\n",
      "Example output: He said the latter was not less wealthy than the most respectable man in the city, but no money is put into his pockets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500 of 3044. Loss:0.19521503150463104. Time:0:31:15\n",
      "Example output: ” said I, “but what wonder shall the lady have dreamed of such such a thing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600 of 3044. Loss:0.32882386445999146. Time:0:33:21\n",
      "Example output: They had no little difficulty in reconciling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1700 of 3044. Loss:0.15023694932460785. Time:0:35:26\n",
      "Example output: But, although I could see no more than a person, and, although I thus saw, still, a gigantic figure, and, although I thus felt him now, although I, as I did, still remained with him, I remained, however, as he fled me through the darkness—while he left me alone in the very dark, undisturbed, and dazed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800 of 3044. Loss:0.22887468338012695. Time:0:37:32\n",
      "Example output: This, however, is not merely a matter of conjecture—that is to say, this is one of the most important topics of discussion in the affairs of science.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1900 of 3044. Loss:0.21478058397769928. Time:0:39:37\n",
      "Example output: When the ship had sailed, and before three days and nine months, she was nearly swooned, and drowned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000 of 3044. Loss:0.24002468585968018. Time:0:41:42\n",
      "Example output: The latter had no chance of any thing, and, having found it too late to make any farther venture, proceeded eagerly, for it had been too late to reap any farther benefits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2100 of 3044. Loss:0.06323030591011047. Time:0:43:47\n",
      "Example output: The rest of the party seemed to be occupied in a variety of endeavors to make them fit into the proper style of the ‘Goosetherumfoodle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200 of 3044. Loss:0.36227625608444214. Time:0:45:53\n",
      "Example output: We reached a small window into the bureau, and, to my surprise, he hesitated to open it, but could not, either, refuse, to open it without our inspection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2300 of 3044. Loss:0.13859443366527557. Time:0:47:58\n",
      "Example output: I now drew from the gutter the lantern, and looked through the aperture to the chamber, and could not see it even as it happened.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400 of 3044. Loss:0.09280868619680405. Time:0:50:04\n",
      "Example output: It was “Old Charley,” as a matter of course.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500 of 3044. Loss:0.2978717088699341. Time:0:52:09\n",
      "Example output: “The skull,” I said.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600 of 3044. Loss:0.1680193990468979. Time:0:54:15\n",
      "Example output: Upon the morning I placed my hand upon her bosom, and my heart became rigid—I thought nothing of the grave, my throat, or my hand upon the floor—my nerves died—I was in dread of my existence, and dreaded, for the moment, my thoughts upon the fate of the girl should be excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2700 of 3044. Loss:0.1964113712310791. Time:0:56:20\n",
      "Example output: “Let us look at the evidence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800 of 3044. Loss:0.455608069896698. Time:0:58:26\n",
      "Example output: The conversation continued for some minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2900 of 3044. Loss:0.08702512085437775. Time:1:00:32\n",
      "Example output: “But let us hurry up the investigation,” said the editor,“and let us hurry it—I see”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000 of 3044. Loss:0.12190612405538559. Time:1:02:38\n",
      "Example output: These latter are the words for the “Dial” on Monday.\n",
      "Average Training Loss: 0.18899476360627565. Epoch time: 1:03:35\n",
      "Evaluating Model\n",
      "Validation loss: 0.21630560092901777. Validation Time: 0:05:11\n",
      "Epoch 3 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 of 3044. Loss:0.0959443747997284. Time:0:02:01\n",
      "Example output: “Hencement!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 of 3044. Loss:0.19467972218990326. Time:0:04:07\n",
      "Example output: It was of course, quite clear that Mr. Pennifeather had no intention of offending, when, having deposited his hold, the dwarf entered into a frantic chase.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 of 3044. Loss:0.16146034002304077. Time:0:06:12\n",
      "Example output: If I had not found him, what chance could I have got of compensation?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 of 3044. Loss:0.19080515205860138. Time:0:08:17\n",
      "Example output: It is no matter to be wondered at.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 of 3044. Loss:0.09353563189506531. Time:0:10:22\n",
      "Example output: The old vale of the coast had, in consequence, had been absorbed in the sea-coast, and would have been absorbed in a line either north or south; but, from the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600 of 3044. Loss:0.1414732038974762. Time:0:12:27\n",
      "Example output: We had put our cards up a chimney, with the hope of discovering some hidden principle in the system, through which, for example, we discovered, by some unaccountable mistake, a very large sum of what is technically “information,” and yet which we believe to have been our design, for that the original letter had not, as yet, any value.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700 of 3044. Loss:0.23160412907600403. Time:0:14:32\n",
      "Example output: I might as well, however, have had a look at my watch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800 of 3044. Loss:0.2297118902206421. Time:0:16:37\n",
      "Example output: —or Baal-Zebub?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900 of 3044. Loss:0.2425803393125534. Time:0:18:42\n",
      "Example output: The walls, although with a heavy weight, had been cut in a tapering seam, but no portion was touched by the nails, and the holes bored so precisely that they gave a distinct impression of the design.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 of 3044. Loss:0.10872698575258255. Time:0:20:47\n",
      "Example output: “The true number,” I continued, “lies in the proportion of the wise individual who have been made to believe them, rather than in the number of the wise individual who have acquired the name”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100 of 3044. Loss:0.1935129165649414. Time:0:22:52\n",
      "Example output: What may ensue, of course, is to make a good diddle of it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200 of 3044. Loss:0.1444370150566101. Time:0:24:58\n",
      "Example output: Yet the truth is, I can scarcely bear to hear the details of his secret deeds—and in the end I cannot bear to hear them—unless, perhaps, I are so profoundly interested in their importance as to put them out to ordinary scrutiny.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300 of 3044. Loss:0.08274431526660919. Time:0:27:03\n",
      "Example output: He was very much astonished at finding that he could not be induced to put up the parchment, because the parchment must have the power of a writing-off—which could have been, if opened, by force of accident, only found under an ordinary person’s ordinary hand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400 of 3044. Loss:0.17993219196796417. Time:0:29:08\n",
      "Example output: Upon recovering, the sailor said he could not be induced to lie down at night; but he kept his eyes upon his own person, and maintained the strict integrity with which he could be expected to behave himself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500 of 3044. Loss:0.1503804326057434. Time:0:31:13\n",
      "Example output: I will call upon the police to seize the premises on Monday, the 9th.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600 of 3044. Loss:0.175868958234787. Time:0:33:18\n",
      "Example output: He grew more and more impatient with the chase.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1700 of 3044. Loss:0.14466983079910278. Time:0:35:22\n",
      "Example output: With him there rolled away the vases, the vaults had been broken, the draperies choked to death, all were dead to see the blackness of the scene.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800 of 3044. Loss:0.3251020908355713. Time:0:37:27\n",
      "Example output: V. Yes, I had no difficulty in conveying this matter to the Prefect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1900 of 3044. Loss:0.13022255897521973. Time:0:39:32\n",
      "Example output: The whole house was very large; and every furniture had been carefully searched, in its vicinity, during one or two nights; and every thing was much alike.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000 of 3044. Loss:0.07899778336286545. Time:0:41:38\n",
      "Example output: “The thing was done, sir,” said the captain, after a pause; “the pieces are all ready, and I am to take my departure for the present day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2100 of 3044. Loss:0.1349535882472992. Time:0:43:43\n",
      "Example output: It is needless to say that I struggled with trepidation to think.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200 of 3044. Loss:0.11680354177951813. Time:0:45:48\n",
      "Example output: The fact is, that the two gentlemen, on the other hand, never really experienced pain in the least, and, having assumed office of the government upon the spot, were, in fact, deputed to duty, and without remuneration, reduced to submission to a duty of duty, in the very proper manner, under the circumstances for the supervision of the police.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2300 of 3044. Loss:0.11038684844970703. Time:0:47:54\n",
      "Example output: The latter had also found it necessary to fasten his head with a pillow, and thus, if possible, to fasten his head in the coffin before the party entered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400 of 3044. Loss:0.10537846386432648. Time:0:49:59\n",
      "Example output: This is by no means a secret; and the only public that is known to believe in this mysterious train of events is by the unanimous opinion of M. Beauvais.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500 of 3044. Loss:0.22446002066135406. Time:0:52:04\n",
      "Example output: “You are astonished at my evident astonishment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600 of 3044. Loss:0.07310800999403. Time:0:54:10\n",
      "Example output: ”   “Keeps the keg up, so you may see how it works.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2700 of 3044. Loss:0.15216301381587982. Time:0:56:15\n",
      "Example output: For the good fortune of his wife I have become absolutely new in her appearance, in her person, and altogether new in her character, and as I have no little difficulty in recognising, you will readily understand that I have spoken of the old lady.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800 of 3044. Loss:0.25573620200157166. Time:0:58:20\n",
      "Example output: He was the sole one, I say, alive; and it was one of a series of accidents that, upon reaching his friend’s house, he discovered, in the open air of a small, black-powder-puncheon, a circular tube of the same nature, slightly interspersed with a circular rim forming a circle of six hundred and seventy yards in diameter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2900 of 3044. Loss:0.12228956073522568. Time:1:00:25\n",
      "Example output: At that moment, too, I was startled into thought, and felt my cheeks close together.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000 of 3044. Loss:0.054683733731508255. Time:1:02:30\n",
      "Example output: My sentiments were of the same order, with sentiments of human interest, and in a sentiment of deep regret, my heart beat heavily and intently within my bosom; and while we spoke, I felt my soul busied in thought, and the day closed at hand.\n",
      "Average Training Loss: 0.15466312444114105. Epoch time: 1:03:28\n",
      "Evaluating Model\n",
      "Validation loss: 0.2208948120660591. Validation Time: 0:05:11\n",
      "Epoch 4 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 of 3044. Loss:0.15953530371189117. Time:0:02:01\n",
      "Example output: It was during this period, however, that I awoke, and as the morning gradually dawns upon darkness, my attention was arrested by the figure of the lost child; and this, in all its fulness and condition of perfect preservation, was, in all its surprising perfection, the very perfection of the mental existence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 of 3044. Loss:0.12367800623178482. Time:0:04:06\n",
      "Example output: Thus it seems that the two most important events, at such a time, have occurred simultaneously.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 of 3044. Loss:0.11916311085224152. Time:0:06:11\n",
      "Example output: We were thus reduced to fifteen by seven in the beginning, and with great difficulty, until we attained a high altitude of seventeen hundred miles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 of 3044. Loss:0.09293688088655472. Time:0:08:16\n",
      "Example output: His principal topics were those of duration and color, with the exception of certain classes of novel characters, whose character has never been in question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 of 3044. Loss:0.12857891619205475. Time:0:10:21\n",
      "Example output: The idea, however, of self-defence seemed inappreciable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600 of 3044. Loss:0.06390029937028885. Time:0:12:27\n",
      "Example output: It is not the object to encumber the whole globe with temples and shrines to the regions beyond Orion; but it is the object, nevertheless, to impress the whole with the idea of a majestic, and inimitable, and inimitable, and in the heart of all men.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700 of 3044. Loss:0.16913077235221863. Time:0:14:32\n",
      "Example output: For a more thorough investigation of this matter I will be permitted to call for aid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800 of 3044. Loss:0.1314568668603897. Time:0:16:37\n",
      "Example output: ”     “We are well off in the South, having just knocked off the roof of a bridge which runs so very nearly off upon the whole of a London bridge—I mean the main one being quite a mile long, and nearly a mile wide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900 of 3044. Loss:0.1326441764831543. Time:0:18:42\n",
      "Example output: But in the end, all that a Frenchman has said of the former, is by no means sure; and, to a Frenchman, an object must be desired.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 of 3044. Loss:0.20609965920448303. Time:0:20:47\n",
      "Example output: The “Diary” is a mere corruption of that which has been already well established in respect to the personal acquaintances of the deceased, and is sufficiently indicative of a sense of propriety and of honor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100 of 3044. Loss:0.07649010419845581. Time:0:22:52\n",
      "Example output: I therefore struggled in vain to force upward the ponderous iron buckle of my hand, lest the buckle, in every crevice, should inevitably fall into the pitcher”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200 of 3044. Loss:0.12780559062957764. Time:0:24:57\n",
      "Example output: When the day broke, it was night, and no light of any kind could be obtained at that particular point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300 of 3044. Loss:0.44168394804000854. Time:0:27:02\n",
      "Example output: ’” And this, in a word, was the sound of an excited imagination.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400 of 3044. Loss:0.0903770923614502. Time:0:29:08\n",
      "Example output: Let me alone, and you will find me intolerable!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500 of 3044. Loss:0.25779837369918823. Time:0:31:13\n",
      "Example output: “We are at a crossroads,” he said.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600 of 3044. Loss:0.07900925725698471. Time:0:33:18\n",
      "Example output: The metaphysicians, it seems, are well aware that the properties of matter are not so greatly varied as those of matter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1700 of 3044. Loss:0.16142727434635162. Time:0:35:23\n",
      "Example output: This done, however, it will be quite an easy matter to get round an axis and send it at a velocity adequate to the purposes proposed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800 of 3044. Loss:0.0825960785150528. Time:0:37:28\n",
      "Example output: —that’s a lie!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1900 of 3044. Loss:0.12697938084602356. Time:0:39:34\n",
      "Example output: I took it for granted that some soul had been disturbed by the sudden disappearance of the cat; and when, at last, its guardian angel wings descended upon my person, I felt no longer the necessity of discharging any ballast into the chamber, and soon found that the creature was, upon my perfect, and without my having attached any portion of my body to its breast, it ceased to exist;—the worm, with its assistance, fell asleep upon my person, and upon my corpse, like a mass of floating rubbish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000 of 3044. Loss:0.06588643789291382. Time:0:41:39\n",
      "Example output: ”     “My lord!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2100 of 3044. Loss:0.05841469019651413. Time:0:43:44\n",
      "Example output: “Now your Excellencies, I wish you to bear in mind that I cannot speak to you of the precise period of my nuptials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200 of 3044. Loss:0.10332237184047699. Time:0:45:49\n",
      "Example output: To-morrow I will make history {*2} of my family, by way of extending the invitation of those noble and sagacious voices in the country, as well as of those well known to the citizens of Rattleborough.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2300 of 3044. Loss:0.09744857996702194. Time:0:47:54\n",
      "Example output: It was the very extraordinary tumult which, although subdued by the violence of human nails, rendered all things perfectly peaceful and easily done, yet did bring to an abrupt termination the horrible reign of the Baron Ritzner von Jung, as well as the terrible infirmity which afterwards embarrassed all the respectable citizens of Ritzner von Jung and the rest of the empire.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400 of 3044. Loss:0.051856812089681625. Time:0:49:59\n",
      "Example output: —that is one of the principal thoroughfares of the Rue Pav?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500 of 3044. Loss:0.093217633664608. Time:0:52:05\n",
      "Example output: The people of this city felt deeply interested, yet they remained silent or abstracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600 of 3044. Loss:0.1119280457496643. Time:0:54:11\n",
      "Example output: These fellows are, you have already said, entitled to a due estimation of the extent of their accomplishments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2700 of 3044. Loss:0.14160145819187164. Time:0:56:16\n",
      "Example output: In his heart he wished for nothing less than death.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800 of 3044. Loss:0.08007431030273438. Time:0:58:21\n",
      "Example output: The result was that the bandage crossed my bosom in an unnatural way.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2900 of 3044. Loss:0.11757238209247589. Time:1:00:26\n",
      "Example output: —who, indeed, could he be dreaming—it is impossible to say—for what could he possibly dreaming, would have been dreaming on its own?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000 of 3044. Loss:0.10439801216125488. Time:1:02:31\n",
      "Example output: It was of a dull grayish-white, the color of the earth.\n",
      "Average Training Loss: 0.1075666684849474. Epoch time: 1:03:28\n",
      "Evaluating Model\n",
      "Validation loss: 0.24512592048978243. Validation Time: 0:05:11\n",
      "Total training took 4:34:57\n"
     ]
    }
   ],
   "source": [
    "story_model = create_model(story_train_dataloader, story_val_dataloader, 'story_model_4_epoch.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUo1Bv6uGUz-"
   },
   "source": [
    "# Generate Story Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17377014,
     "status": "ok",
     "timestamp": 1604003464193,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "DU5a6NwNGTuc",
    "outputId": "4cd12855-9dcd-4f78-f1a0-f7b623d5195d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: He would not—he would not—he would not withdraw his claim to our friendship—to the city of London—would insist upon a little personal foot-bail, after the placing his claim upon some trifling account with a firm and fixed footman, whom he could always catch by the wool.\n",
      "\n",
      "\n",
      "1: This functionary, without much ill-breeding, was of an unassuming and petulant character, and I was sure that he employed it, in a rational way, as if the only natural and convenient vehicle for the exercise of the poetic sentiment.\n",
      "\n",
      "\n",
      "2: ”     “Well, I have no fever to speak, Mounseer Frog, we will take care of you until night, and then, we will take care of you until you return home”.\n",
      "\n",
      "\n",
      "3: There was an air of complacent complaisance pervading every portion of his countenance, and his eye-glass looked fixedly and fixedly forever upon the ceiling, as if the rays of the city upon the earth, and forever upon the moon.\n",
      "\n",
      "\n",
      "4: —must I say?\n",
      "\n",
      "\n",
      "5: You will notice that we have a wild luxuriant influence upon all heavenly objects—is it not?\n",
      "\n",
      "\n",
      "6: I had long been plotting an adventure.\n",
      "\n",
      "\n",
      "7: —very well!\n",
      "\n",
      "\n",
      "8: In his glory he was not a Greek—nor was he a Greek—nor was he more a Russian than a German—nor was he, with the air of a Russian, an effrontery to the classical sensation.\n",
      "\n",
      "\n",
      "9: He grew pale, and became lost in thought; yet, while I gazed, he whispered to me quietly, that although the words were not uttered, the figure had surely perished in the instant.\n",
      "\n",
      "\n",
      "10: And thus—and thus—and thus—and thus—and thus—and thus—it is evident that these are the very words, ‘of the deed’ which act upon the understanding, and which fulfil the promise of the Almighty.\n",
      "\n",
      "\n",
      "11: There are two windows in the chamber, one at each window, and one at each window.\n",
      "\n",
      "\n",
      "12: And then it had become a matter of absolute calculation—for, at a given impulse, the circle was reduced to a limit of no less than one hundred and fifty miles.\n",
      "\n",
      "\n",
      "13: The other day, in the winter of his fourth year, a circular opening was seen fitted in the wall upon the summit of a group of lofty and tawny trees near the mouth of the Piazza.\n",
      "\n",
      "\n",
      "14: In truth, Pierre Bon-Bon was no genius, and he did what no genius would do.\n",
      "\n",
      "\n",
      "15: My chief anxiety was about to test the efficiency of my condenser, by means of a balloon ascension.\n",
      "\n",
      "\n",
      "16: Upon the other hand, you have a very ingenious and very powerful man, myself—a very accomplished and very powerful man.\n",
      "\n",
      "\n",
      "17: There was one resource left me, however, which stood in need of immediate aid.\n",
      "\n",
      "\n",
      "18: I grew sick, and so fell prostrate at once.\n",
      "\n",
      "\n",
      "19: I knew that it was a low, low-pitched room, sixty or seventy feet in diameter, with a gateway, in front, and a ceiling of oak, with a profuse clock and a stylus-piece that hung from the ceiling above.\n",
      "\n",
      "\n",
      "20: It was then suggested that the skull was that of a Saracen ancestor of the family of the Mademoiselle L’Espanaye.\n",
      "\n",
      "\n",
      "21: I did not remove it from its bed-clothes; for I slept until such time as Talbot and myself again slumbered, and were consumed with the intense terror of the task.\n",
      "\n",
      "\n",
      "22: ”     “The body is not disinterred;—no person shall be seen with it.\n",
      "\n",
      "\n",
      "23: I will therefore describe the minute, the moment, and the momentary movements of the animal.\n",
      "\n",
      "\n",
      "24: The result was that the great Kanadaw railroad, in its present form, was scarcely a million of miles, or rather an astounding one.\n",
      "\n",
      "\n",
      "25: But even this most ghastly conception was by no means without danger.\n",
      "\n",
      "\n",
      "26: —it is almost the voice of an Englishman!\n",
      "\n",
      "\n",
      "27: We are cognizant of one another.\n",
      "\n",
      "\n",
      "28: I could see nothing beyond the walls, and a sense of the entire interior was instantly brought to my aid.\n",
      "\n",
      "\n",
      "29: But the Marchesa!\n",
      "\n",
      "\n",
      "30: He has made no attempt at concealing the horrors of his position.\n",
      "\n",
      "\n",
      "31: ’     “We looked for a few days, perhaps to the end of our voyage, and found none.\n",
      "\n",
      "\n",
      "32: I am forced to call your attention to the fact that I have never heard of a man so thoroughly frightened as this very young man was.\n",
      "\n",
      "\n",
      "33: It had been originally written London, but afterwards carefully laid flat upon the tiled floor, by means of a kind of copper; then laid flat again upon the parchment, and the edges pressed together into a circle.\n",
      "\n",
      "\n",
      "34: As, in fact, this body was now entirely buried, and thereunto dragged from the shore of the Barri?\n",
      "\n",
      "\n",
      "35: His Majesty maintains that the sentence, in question, was not thus intended:   ‘Oh, yes; we shall hear the evidence, and we proceed.\n",
      "\n",
      "\n",
      "36: I knew too well, too, how fully he would regard it.\n",
      "\n",
      "\n",
      "37: There was Pompey, Pompey, and Ben-Levi, and Dionysius.\n",
      "\n",
      "\n",
      "38: One day, reading a chapter or two about “Omnipresence” (which I ought to be quoting from the “Cousinaux,”) I fell into some trouble analogous with a misapprehension of the language, which I then carefully and intently hurled upward from the censer.\n",
      "\n",
      "\n",
      "39: —no!\n",
      "\n",
      "\n",
      "40: “And again.\n",
      "\n",
      "\n",
      "41: Thus is it done.\n",
      "\n",
      "\n",
      "42: I wish you also to bear in mind that the reward offered is scarcely in the ratio of its exorbitant prices; and that this reward, we all know, is of no little importance in comparison with that of the usual one proposed; for the true reason, as for obvious reasons, it is in every proportion preputant upon the face of the earth.\n",
      "\n",
      "\n",
      "43: She was then about to ascend from the summit, when the stream broke from the stream and brought up into the main hatchway.\n",
      "\n",
      "\n",
      "44: As it is, the best thing that can be done is to simply roll them up and hang on their beds.\n",
      "\n",
      "\n",
      "45: And now the silence of the night seemed ever-to-night.\n",
      "\n",
      "\n",
      "46: —how could it be otherwise?\n",
      "\n",
      "\n",
      "47: It was a night which had never been spent more tranquilly nor more bitterly together.\n",
      "\n",
      "\n",
      "48: And we came again to the foot of the rainbow, and spoke of the whirl of the Ström, and of the whirl of the Ström, and of the whirl of the Ström, and the whirl of the Ström itself.\n",
      "\n",
      "\n",
      "49: Had not she remained, would not her brother have been more reasonable in supposing her to have remained.\n",
      "\n",
      "\n",
      "50: His footman is a genius; but his tailor is an ungracious blacksmith, tailor, and an adept at cutting and ingressing the works of his apprentices.\n",
      "\n",
      "\n",
      "51: I would have them believe that my sensations in regard to the Angel of the Odd had never been such.\n",
      "\n",
      "\n",
      "52: And as it was, with a heavy heart, I went to work with it in my power”.\n",
      "\n",
      "\n",
      "53: Yet this is a question which I shall not be able to answer.\n",
      "\n",
      "\n",
      "54: This, of course, is somewhat less the ordinary apprehension which may bespeak the presence of a spirit than that which is the habit of mystification, or the secret of its shadows.\n",
      "\n",
      "\n",
      "55: I would have been so glad if I could have been saved from so untimely, if I could have stumbled and fell forward as if by a meteorite, and without either of these I would have been dead.\n",
      "\n",
      "\n",
      "56: Upon each side of us were painted a number indicating the various styles of building.\n",
      "\n",
      "\n",
      "57: He had been awaiting me with impatience, for I had expected to see the mail-robber every ten minutes.\n",
      "\n",
      "\n",
      "58: They are the people of Rattleborough.\n",
      "\n",
      "\n",
      "59: —why, yes!\n",
      "\n",
      "\n",
      "60: In fact, this latter form was now entirely superfluous when I was about to ascend the stairs.\n",
      "\n",
      "\n",
      "61: This was done in a neat parlor; but it was only after much trouble that I succeeded in convincing the host to part with me altogether.\n",
      "\n",
      "\n",
      "62: “A clever fellow!\n",
      "\n",
      "\n",
      "63: —if not exactly in contempt—why, contempt, I beg leave—but in all the little furrows upon my head which lay just under the folds of my fur coat, all bloody and bruised, all covered with the lurid blood of the Scarabaeus.\n",
      "\n",
      "\n",
      "64: But in his first year as superintendent of the cemetery, the Minister was buried beneath a tree, in a very remote part of the town; and, two years previously, I had ventured to visit the grave of the Minister.\n",
      "\n",
      "\n",
      "65: In his rivalry with the king, the two met once or twice in a bottle, when, as he spoke, it occurred to him that the king, having swallowed his wine, had suddenly swallowed it with decision, and thus should have been reduced to drinking the brandy and goblet.\n",
      "\n",
      "\n",
      "66: Here I am forced to make a virtue of necessity—to put an end to the dread of human action.\n",
      "\n",
      "\n",
      "67: At length the captain assented, and entered immediately upon the limb.\n",
      "\n",
      "\n",
      "68: There will be no difficulty in tracing the animal’s general path, through the agency of magnetic or magnetic.\n",
      "\n",
      "\n",
      "69: I spoke no longer—no longer.\n",
      "\n",
      "\n",
      "70: Yet there was something in the air which suggested a vision of human loveliness, and more unequivocally proved the presence of this loveliness in view.\n",
      "\n",
      "\n",
      "71: He said it was a matter of impossibility to prove that the corpse had been kept in its mangled state on shore; and, if so, why, on shore, did it not hang?\n",
      "\n",
      "\n",
      "72: I saw that I breathed, that I spoke, that I felt, that there was something excessively unendurable about the air.\n",
      "\n",
      "\n",
      "73: His Grace had died, at length, after a passionate struggle; but the wounds which had been inflicted upon him by a dozen chained Israelitish prisoners were invisible.\n",
      "\n",
      "\n",
      "74: It is now nearly daybreak, and the sun is scarcely going to be able to shine.\n",
      "\n",
      "\n",
      "75: I had been long in the habit of mesmerizing this same old man repeatedly, for fear of detection, and of course in the end to convince him of my guilt.\n",
      "\n",
      "\n",
      "76: “Then your Majesty,” I said, “you really—you really—you really must have changed.\n",
      "\n",
      "\n",
      "77: It was a small house, with an old moss-covered balustrade, and in one corner was a large rocking-chair, which I could easily see, with the exception that its material was of more importance than that of the couch.\n",
      "\n",
      "\n",
      "78: In about fifteen minutes we had completely broken the loose of the balloon, and in less than five minutes afterward we were safely enough to have regained our original course, when we saw it slip, by a very slight concavity, within the trailing of the stream, and nearly touch-and-go, but fortunately caught it with perfect regularity, after coming down.\n",
      "\n",
      "\n",
      "79: The police, in the meantime, had little object to occupy, but kept a strict watch upon the movements of the young man, and kept strict watch continually upon the whereabouts of the little old gentlemen, while the neighborhood papers, still more obtrusively, still more obtrusively kept an eye upon the affairs of the neighborhood.\n",
      "\n",
      "\n",
      "80: You will know that I speak of these things only in reference to their immediate vicinity; and I have nothing to add to their probability, or to the plausibility, of the idea of collateral injury to my reputation, because, in their supererogation, they have utterly failed to make all duty to their citizens.\n",
      "\n",
      "\n",
      "81: This latter view is of a starry, dull, and indefinite nature.\n",
      "\n",
      "\n",
      "82: I have had occasion, indeed, to observe, or indeed to dream, in the dream of a master of business, the wild yet candid decision of the schoolboy, to divest him, at once, of his worldly advantages, and of his superabundance, when he was growing up, at an early age, from a strong, and rigid attachment of character to his lofty cast of pea-wags, and at a period of deep reflection, upon the delicate condition of his companion, as he grew closer and closer to those lofty and lofty trees, whose tall slender stems and slender stems stood alone in shadow, amid the changing tapestries and shadows of the home and chamber, and the bewildering confusion and uncertainty of his mental existence.\n",
      "\n",
      "\n",
      "83: I called upon Talbot to inform me of my design; and this was the reply I desired—I felt satisfied with having merely spoken to him; but I was too late—I felt deeply interested in the man’s speaking.\n",
      "\n",
      "\n",
      "84: “And what is this world coming to?\n",
      "\n",
      "\n",
      "85: It appears to me obvious that this balloon had never before been in motion, and had never actually departed.\n",
      "\n",
      "\n",
      "86: The whole feat was a mere guess—probably a diddle.\n",
      "\n",
      "\n",
      "87: You are to think of Captain Smitherton; and if you think of any thing about Captain Smitherton, you know he’s a belied man.\n",
      "\n",
      "\n",
      "88: To all appearance he had been dead and buried alive.\n",
      "\n",
      "\n",
      "89: She is of an excellent heart and excellent lungs.\n",
      "\n",
      "\n",
      "90: “Come, allow us go!\n",
      "\n",
      "\n",
      "91: In the meantime there seemed very little demand of the king, and the whole council seemed at a loss to be united.\n",
      "\n",
      "\n",
      "92: But the fact is, we all know the Minister for what has been just said in respect to the affair.\n",
      "\n",
      "\n",
      "93: He now looked toward Madame Lalande, and said no words.\n",
      "\n",
      "\n",
      "94: And now the mystery of this murder, and the very suspicious aspect of the murder itself, became so much heightened that even the very faint idea of motive could scarcely be entertained, even by a man with an imploring heart, of course.\n",
      "\n",
      "\n",
      "95: His hair, as far from it, was a fine black; but upon a trifling part of it he wore a black swate handkerchief, which I had noticed at work in the embroidery.\n",
      "\n",
      "\n",
      "96: In my breast-pocket, I discovered, about a year ago, a somewhat peculiar scarab?\n",
      "\n",
      "\n",
      "97: The other three had fallen asleep in less than half an hour; and all three were now entirely awaking from slumber.\n",
      "\n",
      "\n",
      "98: A single grain of salt was employed—a very good pair of linen.\n",
      "\n",
      "\n",
      "99: I have been assured that I shall never forget the sensations which had so delighted me.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story_model.eval()\n",
    "\n",
    "sample_outputs = story_model.generate(\n",
    "                                generated, \n",
    "                                do_sample=True,   \n",
    "                                top_k=50, \n",
    "                                max_length=512,\n",
    "                                top_p=0.95, \n",
    "                                num_return_sequences=100\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 17377013,
     "status": "ok",
     "timestamp": 1604003464194,
     "user": {
      "displayName": "Scott Duda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRn5vlsP2VP-TM4jPt1ZKBGq1MJCJ2yl5F4D0H=s64",
      "userId": "07461941358185247463"
     },
     "user_tz": 240
    },
    "id": "-YE-3JFF8it1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6ojuAdlpDABj",
    "FVmKeOS_DADy"
   ],
   "name": "Poe GPT-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c03cb12edbd4dffa704a1bf0198e2ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c147b1df0d14336a73811fb85044efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38a0d2b24aab431aa2ce3907e3c4c7ff",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fc0dda773fe5482ba358f55b9b277306",
      "value": 456318
     }
    },
    "15ce4962eac74f758356243cc2f6a7c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b78c07bb081425a9c553f4b018c9e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bbf654d23374169998e2c348facff01",
      "placeholder": "​",
      "style": "IPY_MODEL_15ce4962eac74f758356243cc2f6a7c2",
      "value": " 665/665 [00:12&lt;00:00, 55.4B/s]"
     }
    },
    "1bbf654d23374169998e2c348facff01": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0b30803881441988419227179679b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c03cb12edbd4dffa704a1bf0198e2ce",
      "placeholder": "​",
      "style": "IPY_MODEL_6e644b8638ec46ac85c6873735ad50a0",
      "value": " 548M/548M [00:11&lt;00:00, 46.0MB/s]"
     }
    },
    "1f35359477ea405b9789ff24e250546b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e272f30f056b4cf1b1f92dfe50e045bc",
       "IPY_MODEL_d2172bc18d6a420a8d7e0a1bb3b69e23"
      ],
      "layout": "IPY_MODEL_b70cae5ca73a4ac3a742da150df0d649"
     }
    },
    "24b4fa70fee64177891166b81c279a1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "316c4b609fdc471e8b21a7c9338f19e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "38a0d2b24aab431aa2ce3907e3c4c7ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bc2ae74489c4a3dbb4be0cbbf9ee93b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "516a3444976945be8f0a93810d9c6e03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5547c013bcad4037a328262600d1fafd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7241323cf914ecbb4603ccccd98705f",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bc2ae74489c4a3dbb4be0cbbf9ee93b",
      "value": 665
     }
    },
    "56ac40250b79440bbe0d95933c9ae8e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5763231ceb434c55ad784aa03afbe45d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60d45f1c2fda472da03a8d9a12586cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72008ffdf1b54cf6b17a43a29aa01326",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aaea1ccf6fb94a04b015959525e14c6f",
      "value": 548118077
     }
    },
    "6e644b8638ec46ac85c6873735ad50a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72008ffdf1b54cf6b17a43a29aa01326": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8915376a612e4d4a86797b6b18fead2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_60d45f1c2fda472da03a8d9a12586cbd",
       "IPY_MODEL_1e0b30803881441988419227179679b6"
      ],
      "layout": "IPY_MODEL_24b4fa70fee64177891166b81c279a1d"
     }
    },
    "964d71dc60fe459cb957453e47937e50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47326a853ef432b9585cf96690539f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5547c013bcad4037a328262600d1fafd",
       "IPY_MODEL_1b78c07bb081425a9c553f4b018c9e5c"
      ],
      "layout": "IPY_MODEL_ab04323c16e84978a5f873d13c8ade68"
     }
    },
    "aaea1ccf6fb94a04b015959525e14c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab04323c16e84978a5f873d13c8ade68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b70cae5ca73a4ac3a742da150df0d649": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c337b040a7514d6384b50bece66cb8ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7241323cf914ecbb4603ccccd98705f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2172bc18d6a420a8d7e0a1bb3b69e23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56ac40250b79440bbe0d95933c9ae8e8",
      "placeholder": "​",
      "style": "IPY_MODEL_5763231ceb434c55ad784aa03afbe45d",
      "value": " 1.04M/1.04M [00:01&lt;00:00, 582kB/s]"
     }
    },
    "d32e5580197341898c8817fcef34eb56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_516a3444976945be8f0a93810d9c6e03",
      "placeholder": "​",
      "style": "IPY_MODEL_c337b040a7514d6384b50bece66cb8ed",
      "value": " 456k/456k [00:00&lt;00:00, 913kB/s]"
     }
    },
    "d747e350678543f6ae0c237cecaa6e3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c147b1df0d14336a73811fb85044efd",
       "IPY_MODEL_d32e5580197341898c8817fcef34eb56"
      ],
      "layout": "IPY_MODEL_f6521c70ba724b268103338c2e4d8885"
     }
    },
    "e272f30f056b4cf1b1f92dfe50e045bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_964d71dc60fe459cb957453e47937e50",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_316c4b609fdc471e8b21a7c9338f19e5",
      "value": 1042301
     }
    },
    "f6521c70ba724b268103338c2e4d8885": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc0dda773fe5482ba358f55b9b277306": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
